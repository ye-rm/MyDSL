<!-- Code generated by gomarkdoc. DO NOT EDIT -->

# lexer

```go
import "awesomeDSL/lexer"
```

Package lexer converts the input string into token stream The lexer is responsible for taking the raw input and breaking it into tokens. Example:

```
l := lexer.New(input)
for tok := l.NextToken(); tok.Type != token.EOF; tok = l.NextToken() {
	fmt.Printf("%+v\n", tok)
}
fmt.Printf("%+v\n", tok)
```

## Index

- [type Lexer](<#Lexer>)
  - [func New\(input string\) \*Lexer](<#New>)
  - [func \(l \*Lexer\) NextToken\(\) token.Token](<#Lexer.NextToken>)


<a name="Lexer"></a>
## type [Lexer](<https://github.com/ye-rm/awesomeDSL/blob/master/lexer/lexer.go#L16-L21>)

Lexer struct contains the input string, the current position in the input and the current reading position in the input

```go
type Lexer struct {
    // contains filtered or unexported fields
}
```

<a name="New"></a>
### func [New](<https://github.com/ye-rm/awesomeDSL/blob/master/lexer/lexer.go#L54>)

```go
func New(input string) *Lexer
```

New returns a new Lexer. It takes an input string and returns a pointer to a Lexer It sets the input string, sets the position and readPosition fields to 0 and calls readChar\(\) to initialize the ch field

<a name="Lexer.NextToken"></a>
### func \(\*Lexer\) [NextToken](<https://github.com/ye-rm/awesomeDSL/blob/master/lexer/lexer.go#L72>)

```go
func (l *Lexer) NextToken() token.Token
```

NextToken returns the next token in the input string If the lexer encounters a character it doesnâ€™t know about, it returns an ILLEGAL token

Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)
